{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "from lifelines import WeibullFitter, ExponentialFitter, LogNormalFitter, LogLogisticFitter, LogNormalAFTFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_ready_45.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"AGE_CMV\"] = data[\"AGE\"] * data[\"CMV_STATUS\"]\n",
    "# data[\"VIR_CO_INF\"] = data[\"CMV_STATUS\"] * data[\"EBV_SEROSTATUS\"]\n",
    "# data[\"AGE_BMI_DON\"] = data[\"AGE_DON\"] * data[\"BMI_DON_CALC\"]\n",
    "# data[\"AGE_BMI\"] = data[\"AGE\"] * data[\"BMI_CALC\"]\n",
    "# data[\"DIAB_BMI\"] = data[\"YRS_DIAB\"] * data[\"BMI_CALC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_frame\"] = data[\"time_frame\"] + 1\n",
    "data[\"time_frame\"] = data[\"time_frame\"] / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, stratify=data[\"GRF_STAT_PA\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[[\"time_frame\", \"GRF_STAT_PA\"]]\n",
    "y_real_train = Surv.from_dataframe(\"GRF_STAT_PA\", \"time_frame\", y_train)\n",
    "x_train = train.drop(columns=[\"time_frame\", \"GRF_STAT_PA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test[[\"time_frame\", \"GRF_STAT_PA\"]]\n",
    "\n",
    "x_test = test.drop(columns=[\"time_frame\", \"GRF_STAT_PA\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['PERIP_VASC', 'CREAT_TRR', 'AGE_DON', 'DDAVP_DON', 'CMV_DON', 'BUN_DON',\n",
      "       'SGOT_DON', 'SGPT_DON', 'TBILI_DON', 'CLIN_INFECT_DON',\n",
      "       'HIST_OTH_DRUG_DON', 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'AGE',\n",
      "       'DUCT_MGMT_2', 'PA_PRESERV_TM', 'DIAG_PA_is5001', 'DAYSWAIT_CHRON_PA',\n",
      "       'ORGAN_isKP', 'CMV_IGG', 'EBV_SEROSTATUS', 'CMV_STATUS',\n",
      "       'MED_COND_TRR_is3', 'HGT_CM_CALC', 'WGT_KG_CALC', 'PROTEIN_URINE',\n",
      "       'LIPASE', 'AMYLASE', 'RESUSCIT_DUR', 'INOTROP_SUPPORT_DON', 'YRS_DIAB'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lifelines.LogNormalAFTFitter: fitted with 16908 total observations, 12979 right-censored observations>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Use ElasticNetCV with cross-validation for feature selection\n",
    "elastic_net = ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99], cv=50).fit(x_train, y_train['time_frame'])\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = x_train.columns[(elastic_net.coef_ != 0)]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Fit AFT model with selected features\n",
    "aft = LogNormalAFTFitter()\n",
    "features = list(selected_features) + ['time_frame', 'GRF_STAT_PA']\n",
    "aft.fit(train[features], duration_col='time_frame', event_col='GRF_STAT_PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = Surv.from_dataframe(\"GRF_STAT_PA\", \"time_frame\", y)\n",
    "\n",
    "time_points = np.arange(12, 12*10, 12)\n",
    "\n",
    "preds = aft.predict_cumulative_hazard(df=x_test, times=time_points)\n",
    "\n",
    "auc, mean_auc = cumulative_dynamic_auc(y_real_train, y_real, preds.T, time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic AUC values at different time points:\n",
      "Time 12.00: AUC = 0.757\n",
      "Time 24.00: AUC = 0.750\n",
      "Time 36.00: AUC = 0.727\n",
      "Time 48.00: AUC = 0.736\n",
      "Time 60.00: AUC = 0.745\n",
      "Time 72.00: AUC = 0.744\n",
      "Time 84.00: AUC = 0.730\n",
      "Time 96.00: AUC = 0.724\n",
      "Time 108.00: AUC = 0.723\n",
      "\n",
      "Mean Dynamic AUC: 0.738\n"
     ]
    }
   ],
   "source": [
    "print(\"Dynamic AUC values at different time points:\")\n",
    "for t, auc in zip(time_points, auc):\n",
    "    print(f\"Time {t:.2f}: AUC = {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nMean Dynamic AUC: {mean_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = pd.DataFrame(aft.predict_expectation(x_train), columns=[\"AFT\"])\n",
    "preds_test = pd.DataFrame(aft.predict_expectation(x_test), columns=[\"AFT\"])\n",
    "\n",
    "new_train = pd.concat([train[features], preds_train], axis=1)\n",
    "new_test = pd.concat([test[features], preds_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "cox_model = CoxPHFitter(penalizer=0.1).fit(new_train, duration_col='time_frame', event_col='GRF_STAT_PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cox_train = pd.DataFrame(cox_model.predict_expectation(new_train), columns=[\"COX\"])\n",
    "preds_cox_test = pd.DataFrame(cox_model.predict_expectation(new_test), columns=[\"COX\"])\n",
    "\n",
    "new_cox_train = pd.concat([new_train, preds_cox_train], axis=1)\n",
    "new_cox_test = pd.concat([new_test, preds_cox_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cox_train.to_csv(\"train_aft.csv\", index=False)\n",
    "new_cox_test.to_csv(\"test_aft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the vars in the main table remove for actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"AGE\", \"GENDER\", \"BMI_CALC\", \"YRS_DIAB\", \"AGE_DON\", \"GENDER_DON\", \"BMI_DON_CALC\", \"ORGAN_isKP\", \"DUCT_MGMT_2\", \n",
    "            \"PA_PRESERV_TM\", \"GRF_STAT_PA\", \"time_frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cox_train = train[new_cols]\n",
    "new_cox_test = test[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified 7 numerical variables and 5 binary variables.\n",
      "\n",
      "=== Running MANOVA ===\n",
      "                     Multivariate linear model\n",
      "===================================================================\n",
      "                                                                   \n",
      "-------------------------------------------------------------------\n",
      "       Intercept         Value  Num DF   Den DF    F Value   Pr > F\n",
      "-------------------------------------------------------------------\n",
      "          Wilks' lambda  0.0487 7.0000 21128.0000 58950.9978 0.0000\n",
      "         Pillai's trace  0.9513 7.0000 21128.0000 58950.9978 0.0000\n",
      " Hotelling-Lawley trace 19.5313 7.0000 21128.0000 58950.9978 0.0000\n",
      "    Roy's greatest root 19.5313 7.0000 21128.0000 58950.9978 0.0000\n",
      "-------------------------------------------------------------------\n",
      "                                                                   \n",
      "-------------------------------------------------------------------\n",
      "             group          Value  Num DF   Den DF   F Value Pr > F\n",
      "-------------------------------------------------------------------\n",
      "              Wilks' lambda 0.9997 7.0000 21128.0000  0.9662 0.4540\n",
      "             Pillai's trace 0.0003 7.0000 21128.0000  0.9662 0.4540\n",
      "     Hotelling-Lawley trace 0.0003 7.0000 21128.0000  0.9662 0.4540\n",
      "        Roy's greatest root 0.0003 7.0000 21128.0000  0.9662 0.4540\n",
      "===================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "# ============================ Load Data ============================\n",
    "# Load training and testing datasets\n",
    "\n",
    "\n",
    "# Ensure both datasets have the same columns\n",
    "assert set(new_cox_train.columns) == set(new_cox_test.columns), \"Train and test columns do not match!\"\n",
    "\n",
    "# Identify numerical and binary (categorical) features\n",
    "num_features = [col for col in new_cox_train.columns if new_cox_train[col].nunique() > 2]  # More than 2 unique values\n",
    "binary_features = [col for col in new_cox_test.columns if new_cox_test[col].nunique() == 2]  # Exactly 2 unique values\n",
    "\n",
    "print(f\"\\nIdentified {len(num_features)} numerical variables and {len(binary_features)} binary variables.\")\n",
    "\n",
    "# ============================ MANOVA (Multivariate Test) ============================\n",
    "print(\"\\n=== Running MANOVA ===\")\n",
    "combined_df = pd.concat([new_cox_train.assign(group=\"train\"), new_cox_test.assign(group=\"test\")])  # Merge for MANOVA\n",
    "formula = \" + \".join(num_features)  # Only numerical variables for MANOVA\n",
    "\n",
    "manova = MANOVA.from_formula(f\"{formula} ~ group\", data=combined_df)\n",
    "print(manova.mv_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Combined (Mean ± SD or %)</th>\n",
       "      <th>Train (Mean ± SD or %)</th>\n",
       "      <th>Test (Mean ± SD or %)</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>42.23 (9.12)</td>\n",
       "      <td>42.28 (9.11)</td>\n",
       "      <td>42.05 (9.17)</td>\n",
       "      <td>0.1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>40.73%</td>\n",
       "      <td>40.77%</td>\n",
       "      <td>40.59%</td>\n",
       "      <td>0.8439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMI_CALC</td>\n",
       "      <td>25.48 (4.01)</td>\n",
       "      <td>25.5 (4.01)</td>\n",
       "      <td>25.38 (3.99)</td>\n",
       "      <td>0.0816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YRS_DIAB</td>\n",
       "      <td>26.15 (10.32)</td>\n",
       "      <td>26.14 (10.32)</td>\n",
       "      <td>26.21 (10.33)</td>\n",
       "      <td>0.6899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGE_DON</td>\n",
       "      <td>24.82 (9.07)</td>\n",
       "      <td>24.84 (9.08)</td>\n",
       "      <td>24.76 (9.02)</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENDER_DON</td>\n",
       "      <td>30.82%</td>\n",
       "      <td>30.95%</td>\n",
       "      <td>30.32%</td>\n",
       "      <td>0.4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMI_DON_CALC</td>\n",
       "      <td>23.9 (3.91)</td>\n",
       "      <td>23.9 (3.91)</td>\n",
       "      <td>23.88 (3.9)</td>\n",
       "      <td>0.7180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORGAN_isKP</td>\n",
       "      <td>76.63%</td>\n",
       "      <td>76.56%</td>\n",
       "      <td>76.92%</td>\n",
       "      <td>0.6349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DUCT_MGMT_2</td>\n",
       "      <td>70.6%</td>\n",
       "      <td>70.72%</td>\n",
       "      <td>70.08%</td>\n",
       "      <td>0.4222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PA_PRESERV_TM</td>\n",
       "      <td>11.22 (4.92)</td>\n",
       "      <td>11.22 (4.95)</td>\n",
       "      <td>11.19 (4.8)</td>\n",
       "      <td>0.6770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GRF_STAT_PA</td>\n",
       "      <td>23.24%</td>\n",
       "      <td>23.24%</td>\n",
       "      <td>23.25%</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time_frame</td>\n",
       "      <td>206.1 (153.92)</td>\n",
       "      <td>206.33 (154.14)</td>\n",
       "      <td>205.18 (153.08)</td>\n",
       "      <td>0.6608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Variable Combined (Mean ± SD or %) Train (Mean ± SD or %)  \\\n",
       "0             AGE              42.23 (9.12)           42.28 (9.11)   \n",
       "1          GENDER                    40.73%                 40.77%   \n",
       "2        BMI_CALC              25.48 (4.01)            25.5 (4.01)   \n",
       "3        YRS_DIAB             26.15 (10.32)          26.14 (10.32)   \n",
       "4         AGE_DON              24.82 (9.07)           24.84 (9.08)   \n",
       "5      GENDER_DON                    30.82%                 30.95%   \n",
       "6    BMI_DON_CALC               23.9 (3.91)            23.9 (3.91)   \n",
       "7      ORGAN_isKP                    76.63%                 76.56%   \n",
       "8     DUCT_MGMT_2                     70.6%                 70.72%   \n",
       "9   PA_PRESERV_TM              11.22 (4.92)           11.22 (4.95)   \n",
       "10    GRF_STAT_PA                    23.24%                 23.24%   \n",
       "11     time_frame            206.1 (153.92)        206.33 (154.14)   \n",
       "\n",
       "   Test (Mean ± SD or %)  p-value  \n",
       "0           42.05 (9.17)   0.1423  \n",
       "1                 40.59%   0.8439  \n",
       "2           25.38 (3.99)   0.0816  \n",
       "3          26.21 (10.33)   0.6899  \n",
       "4           24.76 (9.02)   0.5981  \n",
       "5                 30.32%   0.4398  \n",
       "6            23.88 (3.9)   0.7180  \n",
       "7                 76.92%   0.6349  \n",
       "8                 70.08%   0.4222  \n",
       "9            11.19 (4.8)   0.6770  \n",
       "10                23.25%   1.0000  \n",
       "11       205.18 (153.08)   0.6608  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================ Univariate Analysis (Numerical Variables) ============================\n",
    "num_results = {}\n",
    "for col in num_features:\n",
    "    combined_mean = round(combined_df[col].mean(), 2)\n",
    "    train_mean = round(new_cox_train[col].mean(), 2)\n",
    "    test_mean = round(new_cox_test[col].mean(), 2)\n",
    "\n",
    "    combined_std = round(combined_df[col].std(), 2)\n",
    "    train_std = round(new_cox_train[col].std(), 2)\n",
    "    test_std = round(new_cox_test[col].std(), 2)\n",
    "\n",
    "    stat, p = ttest_ind(new_cox_train[col], new_cox_test[col], equal_var=False, nan_policy='omit')\n",
    "    p = round(p, 4)  # Round p-value to 4 decimal places\n",
    "\n",
    "    num_results[col] = [f\"{combined_mean} ({combined_std})\", f\"{train_mean} ({train_std})\", f\"{test_mean} ({test_std})\", p]\n",
    "\n",
    "# ============================ Univariate Analysis (Binary Variables) ============================\n",
    "bin_results = {}\n",
    "for col in binary_features:\n",
    "    combined_percent = round(combined_df[col].mean() * 100, 2)  # Percentage of 1s\n",
    "    train_percent = round(new_cox_train[col].mean() * 100, 2)\n",
    "    test_percent = round(new_cox_test[col].mean() * 100, 2)\n",
    "\n",
    "    contingency_table = pd.crosstab(combined_df[col], combined_df[\"group\"])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    p = round(p, 4)  # Round p-value\n",
    "\n",
    "    bin_results[col] = [f\"{combined_percent}%\", f\"{train_percent}%\", f\"{test_percent}%\", p]\n",
    "\n",
    "# ============================ Create Final Table with Preserved Row Order ============================\n",
    "final_results = []\n",
    "for col in new_cox_train.columns:  # Preserve original column order\n",
    "    if col in num_results:\n",
    "        final_results.append([col] + num_results[col])\n",
    "    elif col in bin_results:\n",
    "        final_results.append([col] + bin_results[col])\n",
    "\n",
    "# Create DataFrame with correct order\n",
    "final_table = pd.DataFrame(\n",
    "    final_results,\n",
    "    columns=[\"Variable\", \"Combined (Mean ± SD or %)\", \"Train (Mean ± SD or %)\", \"Test (Mean ± SD or %)\", \"p-value\"]\n",
    ")\n",
    "\n",
    "# Print final table\n",
    "final_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
