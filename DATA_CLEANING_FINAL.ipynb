{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\381285905.py:1: DtypeWarning: Columns (3,6,9,18,19,20,21,22,23,24,28,29,30,31,32,34,35,36,37,38,39,45,46,47,48,49,52,53,54,55,66,67,70,72,74,75,76,77,78,79,82,83,84,85,86,87,88,89,90,91,92,93,94,103,104,106,112,115,116,117,120,122,123,132,134,135,136,138,140,141,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,169,171,173,175,176,177,178,179,180,181,182,183,184,188,189,190,191,193,199,200,202,203,204,207,208,209,210,211,212,213,214,216,217,222,223,224,225,226,227,228,234,236,237,242,243,248,253,255,260,261,262,263,264,266,267,268,269,270,271,277,280,281,283,285,287,289,290,294,295,296,297,299,300,301,302,303,306,308,317,321,328,330,332,347,352,357,358,365,366,367,368,372,379,382,386,387,388,393,410,411,412,413,414,421,422,429,430,431,432,433,434,435,436,438,442,455,456,457,458,459,468,469,470,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PAN_data = pd.read_csv(\"PAN_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "PAN_data = pd.read_csv(\"PAN_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_94 = pd.to_datetime(\"04/01/1994\", dayfirst=False)\n",
    "pan_data_after_94 = PAN_data.copy()\n",
    "pan_data_after_94[\"TX_DATE\"] = pd.to_datetime(pan_data_after_94[\"TX_DATE\"], dayfirst=False)\n",
    "pan_data_after_94 = pan_data_after_94[pan_data_after_94[\"TX_DATE\"] > after_94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = [\n",
    "    \"GENDER\", \"DAYSWAIT_CHRON\", \"PERIP_VASC\", \"AGE_DIAB\",\n",
    "    \"TX_DATE\", \"CREAT_TRR\",\n",
    "    \"AMIS\", \"BMIS\", \"DRMIS\", \"HLAMIS\", \"NPKID\", \"NPPAN\", \"AGE_DON\", \"DDAVP_DON\", \"CMV_DON\",\n",
    "    \"COD_CAD_DON\", \"DEATH_CIRCUM_DON\", \"DEATH_MECH_DON\", \"GENDER_DON\",\n",
    "    \"NON_HRT_DON\", \"ANTIHYPE_DON\", \"BUN_DON\", \"CREAT_DON\", \n",
    "    \"PT_DIURETICS_DON\", \"PT_STEROIDS_DON\", \"PT_T3_DON\", \"PT_T4_DON\", \"SGOT_DON\",\n",
    "    \"SGPT_DON\", \"TBILI_DON\", \"VASODIL_DON\", \"CLIN_INFECT_DON\", \"HIST_CIG_DON\",\n",
    "    \"HIST_HYPERTENS_DON\", \"HIST_COCAINE_DON\", \"HIST_OTH_DRUG_DON\", \"HEPARIN_DON\", \"HGT_CM_DON_CALC\", \"WGT_KG_DON_CALC\",\n",
    "    \"BMI_DON_CALC\", \"ABO_MAT\", \"AGE\", \"DIAL_TRR\", \"ART_RECON\", \"DUCT_MGMT\", \"GRF_PLACEM\",\n",
    "    \"PA_PRESERV_TM\", \"VASC_MGMT\", \"VEN_EXT_GRF\", \"FAILDATE_PA\", \"DIAG_PA\", \"GRF_STAT_PA\",\n",
    "    \"DAYSWAIT_CHRON_PA\", \"EBV_SEROSTATUS\", \"HBV_CORE\",\n",
    "    \"HCV_SEROSTATUS\", \"CMV_STATUS\", \n",
    "    \"TX_TYPE\", \"MALIG\", \"HGT_CM_CALC\", \"WGT_KG_CALC\", \"BMI_CALC\", \"OPER_TECH\",\n",
    "    \"PROTEIN_URINE\", \"LIPASE\", \"AMYLASE\", \"CARDARREST_NEURO\", \"INOTROP_SUPPORT_DON\", \"PX_STAT_DATE\", \"PX_STAT\", \n",
    "    \"REM_CD\", \"AGE_GROUP\", \"DON_TY\", \"MULTIORG\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = pan_data_after_94[my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\2907620572.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\2907620572.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])\n"
     ]
    }
   ],
   "source": [
    "# convert the reason of removal to numeric and only include those that underwent transplantation [2,3,4,14,15,18,19]\n",
    "clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
    "clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = clean_good[clean_good[\"REM_CD\"].isin([2,3,4,14,15,18,19])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ABO</th>\n",
       "      <th>DAYSWAIT_CHRON</th>\n",
       "      <th>PERIP_VASC</th>\n",
       "      <th>AGE_DIAB</th>\n",
       "      <th>TX_DATE</th>\n",
       "      <th>CREAT_TRR</th>\n",
       "      <th>AMIS</th>\n",
       "      <th>BMIS</th>\n",
       "      <th>DRMIS</th>\n",
       "      <th>...</th>\n",
       "      <th>LIPASE</th>\n",
       "      <th>AMYLASE</th>\n",
       "      <th>CARDARREST_NEURO</th>\n",
       "      <th>INOTROP_SUPPORT_DON</th>\n",
       "      <th>PX_STAT_DATE</th>\n",
       "      <th>PX_STAT</th>\n",
       "      <th>REM_CD</th>\n",
       "      <th>AGE_GROUP</th>\n",
       "      <th>DON_TY</th>\n",
       "      <th>MULTIORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>AB</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1994-06-11</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>06/21/1994</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>AB</td>\n",
       "      <td>411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1995-04-18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>01/16/2003</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1995-07-29</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>05/04/1998</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>07/04/2004</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>1383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1997-01-17</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>12/28/1999</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37499</th>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>16</td>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37500</th>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>17</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-17</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501</th>\n",
       "      <td>M</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37502</th>\n",
       "      <td>F</td>\n",
       "      <td>O</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37503</th>\n",
       "      <td>F</td>\n",
       "      <td>AB</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34162 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GENDER ABO DAYSWAIT_CHRON PERIP_VASC AGE_DIAB    TX_DATE CREAT_TRR AMIS  \\\n",
       "0          M  AB            101        NaN        . 1994-06-11      2.90    1   \n",
       "1          F  AB            411        NaN        . 1995-04-18      1.00    0   \n",
       "2          F   O            731        NaN        . 1995-07-29      1.30    0   \n",
       "3          F   O            875        NaN        . 1995-09-01      1.20    1   \n",
       "4          F   O           1383        NaN        . 1997-01-17      0.60    0   \n",
       "...      ...  ..            ...        ...      ...        ...       ...  ...   \n",
       "37499      F   O             23          N       16 2024-03-21         .    2   \n",
       "37500      F   B             17          N        2 2024-03-17         .    1   \n",
       "37501      M   O              4          N       12 2024-03-11         .    2   \n",
       "37502      F   O              9        NaN        . 2024-03-20         .    1   \n",
       "37503      F  AB             16          N       10 2024-03-29         .    0   \n",
       "\n",
       "      BMIS DRMIS  ... LIPASE  AMYLASE  CARDARREST_NEURO INOTROP_SUPPORT_DON  \\\n",
       "0        2     2  ...      .        .                 U                   N   \n",
       "1        1     0  ...      .        .                 U                   N   \n",
       "2        1     2  ...      .        .                 U                   N   \n",
       "3        1     1  ...      .        .                 U                   N   \n",
       "4        1     0  ...      .        .                 U                   N   \n",
       "...    ...   ...  ...    ...      ...               ...                 ...   \n",
       "37499    2     2  ...      .        .               NaN                 NaN   \n",
       "37500    2     2  ...      .        .               NaN                 NaN   \n",
       "37501    2     1  ...      .        .               NaN                 NaN   \n",
       "37502    2     2  ...  20.00    87.00                 N                   Y   \n",
       "37503    2     2  ...      .        .               NaN                 NaN   \n",
       "\n",
       "      PX_STAT_DATE PX_STAT REM_CD AGE_GROUP DON_TY MULTIORG  \n",
       "0       06/21/1994       D      4         A      C      NaN  \n",
       "1       01/16/2003       D      4         A      C      NaN  \n",
       "2       05/04/1998       D      4         A      C      NaN  \n",
       "3       07/04/2004       R      4         A      C      NaN  \n",
       "4       12/28/1999       L      4         A      C      NaN  \n",
       "...            ...     ...    ...       ...    ...      ...  \n",
       "37499            .     NaN      4         A      C      NaN  \n",
       "37500            .     NaN      4         A      C      NaN  \n",
       "37501            .     NaN      4         A      C      NaN  \n",
       "37502            .     NaN      4         A      C      NaN  \n",
       "37503            .     NaN      4         A      C      NaN  \n",
       "\n",
       "[34162 rows x 76 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34024, 76)\n"
     ]
    }
   ],
   "source": [
    "#remove very recent transplants\n",
    "\n",
    "clean_good = clean_good[clean_good[\"PX_STAT_DATE\"] != \".\"]\n",
    "print(clean_good.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\3346024158.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\3346024158.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)\n"
     ]
    }
   ],
   "source": [
    "clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
    "clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\4063916721.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"time_frame\"] = clean_good[\"PX_STAT_DATE\"] - clean_good[\"TX_DATE\"]\n"
     ]
    }
   ],
   "source": [
    "clean_good[\"time_frame\"] = clean_good[\"PX_STAT_DATE\"] - clean_good[\"TX_DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_5756\\2960106135.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"time_frame\"] = clean_good[\"time_frame\"].dt.days\n"
     ]
    }
   ],
   "source": [
    "#only include those with more than 5 years of followup\n",
    "clean_good[\"time_frame\"] = clean_good[\"time_frame\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_good = clean_good.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.to_datetime(\"04/04/2019\", dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove transplants with less than 5 years of followup time\n",
    "#clean_good = clean_good[clean_good[\"TX_DATE\"] < cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34024, 77)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = clean_good.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = very_clean_data[very_clean_data[\"AGE_GROUP\"] == \"A\"]\n",
    "\n",
    "very_clean_data = very_clean_data[very_clean_data[\"DON_TY\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = very_clean_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"HLAMIS\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33004, 77)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pre_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pre_imp[\"5YR_SURV\"] = pd.Series(dtype=\"int\")\n",
    "# data_pre_imp[\"index\"] = range(33004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23436, 77)\n",
      "(23431, 77)\n"
     ]
    }
   ],
   "source": [
    "#grafts that survived five years\n",
    "surv = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"Y\"]\n",
    "print(surv.shape)\n",
    "surv = surv[surv[\"FAILDATE_PA\"] == \".\"]\n",
    "print(surv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 77)\n",
      "(9559, 77)\n",
      "(9559, 77)\n",
      "(9559, 78)\n",
      "(9559, 78)\n",
      "(9559, 77)\n"
     ]
    }
   ],
   "source": [
    "#grafts that failed in the first five years but here we are using the dataset including all transplants \n",
    "# because if a transplant done in 2021 failed in 1 year it should still be taken into account\n",
    "fail = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"N\"]\n",
    "print(fail.shape)\n",
    "#drop data wihtout fail date\n",
    "fail = fail[fail[\"FAILDATE_PA\"] != \".\"]\n",
    "print(fail.shape)\n",
    "fail[\"FAILDATE_PA\"] = pd.to_datetime(fail[\"FAILDATE_PA\"], dayfirst=False)\n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"FAILDATE_PA\"] - fail[\"TX_DATE\"] \n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"fail_frame\"].dt.days\n",
    "print(fail.shape)\n",
    "fail[\"time_frame\"] = fail[\"fail_frame\"]\n",
    "fail = fail.drop(columns=[\"fail_frame\"], axis=1)\n",
    "print(fail.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed_after_5 = failed_after_5.drop(\"fail_frame\", axis=1)\n",
    "# fail = fail.drop(\"fail_frame\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [surv, fail]\n",
    "labelled_pre_imp = pd.concat(frames)\n",
    "labelled_pre_imp = data_pre_imp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelled_pre_imp = labelled_pre_imp.sort_values(['index'])\n",
    "no_longer_needed = [\"PX_STAT_DATE\", \"PX_STAT\", \"FAILDATE_PA\", \n",
    "                    \"TX_DATE\", \"AGE_GROUP\", \"DON_TY\", \"REM_CD\"]\n",
    "labelled_pre_imp = labelled_pre_imp.drop(columns=no_longer_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 86 donors with unkown height or weight or both\n",
    "labelled_pre_imp = labelled_pre_imp[labelled_pre_imp[\"BMI_DON_CALC\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = labelled_pre_imp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(imputation):\n",
    "    # Replace missing values with \"U\" in column: 'PERIP_VASC'\n",
    "    imputation = imputation.fillna({'PERIP_VASC': \"U\"})\n",
    "  # Change column type to int32 for column: 'AMIS'\n",
    "    imputation = imputation.astype({'AMIS': 'int32'})\n",
    "    # Change column type to int32 for columns: 'BMIS', 'DRMIS', 'HLAMIS'\n",
    "    imputation = imputation.astype({'BMIS': 'int32', 'DRMIS': 'int32', 'HLAMIS': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE_DON'\n",
    "    imputation = imputation.astype({'AGE_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DDAVP_DON'\n",
    "    imputation = imputation.fillna({'DDAVP_DON': \"U\"})\n",
    "    # Replace missing values with \"N\" in column: 'CMV_DON'\n",
    "    imputation = imputation.fillna({'CMV_DON': \"N\"})\n",
    "    # Replace all instances of \"ND\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"I\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"I\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"C\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"C\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"P\" with \"1\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    \n",
    "   # Replace missing values with \"N\" in column: 'NON_HRT_DON'\n",
    "    imputation = imputation.fillna({'NON_HRT_DON': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'ANTIHYPE_DON'\n",
    "    imputation = imputation.fillna({'ANTIHYPE_DON': \"U\"})\n",
    "   # Change column type to string for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'BUN_DON'\n",
    "    imputation.loc[imputation['BUN_DON'].str.lower() == \".\".lower(), 'BUN_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'BUN_DON'\n",
    "    imputation = imputation.fillna({'BUN_DON': imputation['BUN_DON'].median()})\n",
    "    # Change column type to string for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_DON'\n",
    "    imputation.loc[imputation['CREAT_DON'].str.lower() == \".\".lower(), 'CREAT_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_DON'\n",
    "    imputation = imputation.fillna({'CREAT_DON': imputation['CREAT_DON'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'PT_DIURETICS_DON'\n",
    "    imputation = imputation.fillna({'PT_DIURETICS_DON': \"U\"})\n",
    "   \n",
    "    # Replace missing values with \"U\" in column: 'PT_STEROIDS_DON'\n",
    "    imputation = imputation.fillna({'PT_STEROIDS_DON': \"U\"})\n",
    "   # Replace missing values with \"U\" in column: 'PT_T3_DON'\n",
    "    imputation = imputation.fillna({'PT_T3_DON': \"U\"})\n",
    "     # Replace missing values with \"U\" in column: 'PT_T4_DON'\n",
    "    imputation = imputation.fillna({'PT_T4_DON': \"U\"})\n",
    "   # Change column type to string for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'string', 'SGPT_DON': 'string', 'TBILI_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation.loc[imputation['SGOT_DON'].str.lower() == \".\".lower(), 'SGOT_DON'] = np.nan\n",
    "    imputation.loc[imputation['SGPT_DON'].str.lower() == \".\".lower(), 'SGPT_DON'] = np.nan\n",
    "    imputation.loc[imputation['TBILI_DON'].str.lower() == \".\".lower(), 'TBILI_DON'] = np.nan\n",
    "    # Change column type to float32 for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'float32', 'SGPT_DON': 'float32', 'TBILI_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.fillna({'SGOT_DON': imputation['SGOT_DON'].median(), 'SGPT_DON': imputation['SGPT_DON'].median(), 'TBILI_DON': imputation['TBILI_DON'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'VASODIL_DON'\n",
    "    imputation = imputation.fillna({'VASODIL_DON': \"U\"})\n",
    "    # Replace missing values with \"U\" in column: 'CLIN_INFECT_DON'\n",
    "    imputation = imputation.fillna({'CLIN_INFECT_DON': \"U\"})\n",
    "    \n",
    "    # Replace missing values with \"U\" in column: 'HIST_CIG_DON'\n",
    "    imputation = imputation.fillna({'HIST_CIG_DON': \"U\"})\n",
    "    # Replace missing values with \"U\" in columns: 'HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON'\n",
    "    imputation = imputation.fillna({'HIST_COCAINE_DON': \"U\", 'HIST_HYPERTENS_DON': \"U\", 'HIST_OTH_DRUG_DON': \"U\"})\n",
    " # Replace missing values with \"U\" in column: 'HEPARIN_DON'\n",
    "    imputation = imputation.fillna({'HEPARIN_DON': \"U\"})\n",
    "    # Change column type to int32 for column: 'ABO_MAT'\n",
    "    imputation = imputation.astype({'ABO_MAT': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE'\n",
    "    imputation = imputation.astype({'AGE': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DIAL_TRR'\n",
    "    imputation = imputation.fillna({'DIAL_TRR': \"U\"})\n",
    "     # Replace missing values with \"0\" in column: 'MULTIORG'\n",
    "    imputation = imputation.fillna({'MULTIORG': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'MULTIORG'\n",
    "    imputation['MULTIORG'] = imputation['MULTIORG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'MULTIORG'\n",
    "    imputation = imputation.astype({'MULTIORG': 'int32'})\n",
    "    # Change column type to string for column: 'ART_RECON'\n",
    "    imputation = imputation.astype({'ART_RECON': 'string'})\n",
    "    # Replace all instances of \".\" with \"2\" in column: 'ART_RECON'\n",
    "    imputation['ART_RECON'] = imputation['ART_RECON'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # Change column type to string for column: 'DUCT_MGMT'\n",
    "    imputation = imputation.astype({'DUCT_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"999\" in column: 'DUCT_MGMT'\n",
    "    imputation['DUCT_MGMT'] = imputation['DUCT_MGMT'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # Change column type to string for column: 'GRF_PLACEM'\n",
    "    imputation = imputation.astype({'GRF_PLACEM': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'GRF_PLACEM'\n",
    "    imputation['GRF_PLACEM'] = imputation['GRF_PLACEM'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \".\" with \"\" in column: 'PA_PRESERV_TM'\n",
    "    imputation.loc[imputation['PA_PRESERV_TM'].str.lower() == \".\".lower(), 'PA_PRESERV_TM'] = np.nan\n",
    "    # Change column type to float32 for column: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.astype({'PA_PRESERV_TM': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.fillna({'PA_PRESERV_TM': imputation['PA_PRESERV_TM'].median()})\n",
    "\n",
    "    # Change column type to string for column: 'VASC_MGMT'\n",
    "    imputation = imputation.astype({'VASC_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'VASC_MGMT'\n",
    "    imputation['VASC_MGMT'] = imputation['VASC_MGMT'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # Replace missing values with \"N\" in column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.fillna({'VEN_EXT_GRF': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.astype({'VEN_EXT_GRF': 'int32'})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Change column type to string for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation.loc[imputation['DAYSWAIT_CHRON_PA'].str.lower() == \".\".lower(), 'DAYSWAIT_CHRON_PA'] = np.nan\n",
    "    # Change column type to float32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.fillna({'DAYSWAIT_CHRON_PA': imputation['DAYSWAIT_CHRON_PA'].median()})\n",
    "    # Change column type to int32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'int32'})\n",
    "    imputation['HBV_CORE'] = imputation['HBV_CORE'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['HCV_SEROSTATUS'] = imputation['HCV_SEROSTATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['CMV_STATUS'] = imputation['CMV_STATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # Replace missing values with \"U\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation = imputation.fillna({'EBV_SEROSTATUS': \"U\"})\n",
    "   # Change column type to string for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'string', 'WGT_KG_CALC': 'string', 'BMI_CALC': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'HGT_CM_CALC'\n",
    "    imputation.loc[imputation['HGT_CM_CALC'].str.lower() == \".\".lower(), 'HGT_CM_CALC'] = np.nan\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation.loc[imputation['WGT_KG_CALC'].str.lower() == \".\".lower(), 'WGT_KG_CALC'] = np.nan\n",
    "    imputation.loc[imputation['BMI_CALC'].str.lower() == \".\".lower(), 'BMI_CALC'] = np.nan\n",
    "    # Change column type to float32 for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'float32', 'WGT_KG_CALC': 'float32', 'BMI_CALC': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.fillna({'HGT_CM_CALC': imputation['HGT_CM_CALC'].median(), 'WGT_KG_CALC': imputation['WGT_KG_CALC'].median(), 'BMI_CALC': imputation['BMI_CALC'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'PROTEIN_URINE'\n",
    "    imputation = imputation.fillna({'PROTEIN_URINE': \"U\"})\n",
    "    # Replace missing values with \"U\" in column: 'CARDARREST_NEURO'\n",
    "    imputation = imputation.fillna({'CARDARREST_NEURO': \"U\"})\n",
    "   # Replace missing values with \"U\" in column: 'INOTROP_SUPPORT_DON'\n",
    "    imputation = imputation.fillna({'INOTROP_SUPPORT_DON': \"U\"})\n",
    "\n",
    "    # Change column type to int32 for column: 'ETHCAT'\n",
    "    # Replace all instances of \".\" with \"\" in column: 'AGE_DIAB'\n",
    "    imputation.loc[imputation['AGE_DIAB'].str.lower() == \".\".lower(), 'AGE_DIAB'] = np.nan\n",
    "    # Change column type to float32 for column: 'AGE_DIAB'\n",
    "    imputation = imputation.astype({'AGE_DIAB': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'AGE_DIAB'\n",
    "    imputation = imputation.fillna({'AGE_DIAB': imputation['AGE_DIAB'].median()})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_TRR'\n",
    "    imputation.loc[imputation['CREAT_TRR'].str.lower() == \".\".lower(), 'CREAT_TRR'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_TRR'\n",
    "    imputation = imputation.astype({'CREAT_TRR': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_TRR'\n",
    "    imputation = imputation.fillna({'CREAT_TRR': imputation['CREAT_TRR'].median()})\n",
    "    # Change column type to string for column: 'ETHCAT_DON'\n",
    "    # Change column type to float32 for columns: 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'BMI_DON_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_DON_CALC': 'float32', 'WGT_KG_DON_CALC': 'float32', 'BMI_DON_CALC': 'float32'})\n",
    "    # Round column 'BMI_DON_CALC' (Number of decimals: 1)\n",
    "    imputation = imputation.round({'BMI_DON_CALC': 1})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"5001\" in column: 'DIAG_PA'\n",
    "    imputation['DIAG_PA'] = imputation['DIAG_PA'].str.replace(\".\", \"5001\", case=False, regex=False)\n",
    "    return imputation\n",
    "   \n",
    "\n",
    "\n",
    "imputation_clean_no_oh = clean_data(imputation.copy())\n",
    "\n",
    "imputation_new = clean_data(imputation.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(imputation_clean_no_oh):\n",
    "    # Replace all instances of \"M\" with \"0\" in column: 'GENDER'\n",
    "    imputation_clean_no_oh['GENDER'] = imputation_clean_no_oh['GENDER'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"F\" with \"1\" in column: 'GENDER'\n",
    "    imputation_clean_no_oh['GENDER'] = imputation_clean_no_oh['GENDER'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    # Change column type to float32 for column: 'GENDER'\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.astype({'GENDER': 'float32'})\n",
    "    # Replace all instances of \"A1\" with \"A\" in column: 'ABO'\n",
    "    imputation_clean_no_oh['ABO'] = imputation_clean_no_oh['ABO'].str.replace(\"A1\", \"A\", case=False, regex=False)\n",
    "    # Replace all instances of \"A2\" with \"\" in column: 'ABO'\n",
    "    imputation_clean_no_oh['ABO'] = imputation_clean_no_oh['ABO'].str.replace(\"A2\", \"\", case=False, regex=False)\n",
    "    # Replace all instances of \"\" with \"\" in column: 'ABO'\n",
    "    imputation_clean_no_oh.loc[imputation_clean_no_oh['ABO'].str.lower() == \"\".lower(), 'ABO'] = \"A\"\n",
    "    # One-hot encode column: 'ABO'\n",
    "    insert_loc = imputation_clean_no_oh.columns.get_loc('ABO')\n",
    "    imputation_clean_no_oh = pd.concat([imputation_clean_no_oh.iloc[:,:insert_loc], pd.get_dummies(imputation_clean_no_oh.loc[:, ['ABO']]), imputation_clean_no_oh.iloc[:,insert_loc+1:]], axis=1)\n",
    "\n",
    "    # Replace all instances of \"U\" with \"0\" in column: 'PERIP_VASC'\n",
    "    imputation_clean_no_oh['PERIP_VASC'] = imputation_clean_no_oh['PERIP_VASC'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in columns: 'PERIP_VASC', 'DDAVP_DON' and 17 other columns\n",
    "    imputation_clean_no_oh['PERIP_VASC'] = imputation_clean_no_oh['PERIP_VASC'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['DDAVP_DON'] = imputation_clean_no_oh['DDAVP_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['ANTIHYPE_DON'] = imputation_clean_no_oh['ANTIHYPE_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_DIURETICS_DON'] = imputation_clean_no_oh['PT_DIURETICS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_STEROIDS_DON'] = imputation_clean_no_oh['PT_STEROIDS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_T3_DON'] = imputation_clean_no_oh['PT_T3_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_T4_DON'] = imputation_clean_no_oh['PT_T4_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['VASODIL_DON'] = imputation_clean_no_oh['VASODIL_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CLIN_INFECT_DON'] = imputation_clean_no_oh['CLIN_INFECT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_CIG_DON'] = imputation_clean_no_oh['HIST_CIG_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_COCAINE_DON'] = imputation_clean_no_oh['HIST_COCAINE_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_HYPERTENS_DON'] = imputation_clean_no_oh['HIST_HYPERTENS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_OTH_DRUG_DON'] = imputation_clean_no_oh['HIST_OTH_DRUG_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HEPARIN_DON'] = imputation_clean_no_oh['HEPARIN_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['DIAL_TRR'] = imputation_clean_no_oh['DIAL_TRR'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['MALIG'] = imputation_clean_no_oh['MALIG'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PROTEIN_URINE'] = imputation_clean_no_oh['PROTEIN_URINE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CARDARREST_NEURO'] = imputation_clean_no_oh['CARDARREST_NEURO'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['INOTROP_SUPPORT_DON'] = imputation_clean_no_oh['INOTROP_SUPPORT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in columns: 'PERIP_VASC', 'DDAVP_DON' and 17 other columns\n",
    "    imputation_clean_no_oh['PERIP_VASC'] = imputation_clean_no_oh['PERIP_VASC'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['DDAVP_DON'] = imputation_clean_no_oh['DDAVP_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['ANTIHYPE_DON'] = imputation_clean_no_oh['ANTIHYPE_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_DIURETICS_DON'] = imputation_clean_no_oh['PT_DIURETICS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_STEROIDS_DON'] = imputation_clean_no_oh['PT_STEROIDS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_T4_DON'] = imputation_clean_no_oh['PT_T4_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_T3_DON'] = imputation_clean_no_oh['PT_T3_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['VASODIL_DON'] = imputation_clean_no_oh['VASODIL_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CLIN_INFECT_DON'] = imputation_clean_no_oh['CLIN_INFECT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_CIG_DON'] = imputation_clean_no_oh['HIST_CIG_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_COCAINE_DON'] = imputation_clean_no_oh['HIST_COCAINE_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_HYPERTENS_DON'] = imputation_clean_no_oh['HIST_HYPERTENS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_OTH_DRUG_DON'] = imputation_clean_no_oh['HIST_OTH_DRUG_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HEPARIN_DON'] = imputation_clean_no_oh['HEPARIN_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['DIAL_TRR'] = imputation_clean_no_oh['DIAL_TRR'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['MALIG'] = imputation_clean_no_oh['MALIG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PROTEIN_URINE'] = imputation_clean_no_oh['PROTEIN_URINE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CARDARREST_NEURO'] = imputation_clean_no_oh['CARDARREST_NEURO'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['INOTROP_SUPPORT_DON'] = imputation_clean_no_oh['INOTROP_SUPPORT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"0\" in columns: 'PERIP_VASC', 'DDAVP_DON' and 17 other columns\n",
    "    imputation_clean_no_oh['PERIP_VASC'] = imputation_clean_no_oh['PERIP_VASC'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['DDAVP_DON'] = imputation_clean_no_oh['DDAVP_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['ANTIHYPE_DON'] = imputation_clean_no_oh['ANTIHYPE_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_DIURETICS_DON'] = imputation_clean_no_oh['PT_DIURETICS_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_STEROIDS_DON'] = imputation_clean_no_oh['PT_STEROIDS_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_T3_DON'] = imputation_clean_no_oh['PT_T3_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PT_T4_DON'] = imputation_clean_no_oh['PT_T4_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['VASODIL_DON'] = imputation_clean_no_oh['VASODIL_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CLIN_INFECT_DON'] = imputation_clean_no_oh['CLIN_INFECT_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_CIG_DON'] = imputation_clean_no_oh['HIST_CIG_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_COCAINE_DON'] = imputation_clean_no_oh['HIST_COCAINE_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_HYPERTENS_DON'] = imputation_clean_no_oh['HIST_HYPERTENS_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HIST_OTH_DRUG_DON'] = imputation_clean_no_oh['HIST_OTH_DRUG_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HEPARIN_DON'] = imputation_clean_no_oh['HEPARIN_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['DIAL_TRR'] = imputation_clean_no_oh['DIAL_TRR'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['MALIG'] = imputation_clean_no_oh['MALIG'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['PROTEIN_URINE'] = imputation_clean_no_oh['PROTEIN_URINE'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CARDARREST_NEURO'] = imputation_clean_no_oh['CARDARREST_NEURO'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['INOTROP_SUPPORT_DON'] = imputation_clean_no_oh['INOTROP_SUPPORT_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "   # Replace all instances of \"A1\" with \"A\" in column: 'ABO_DON'\n",
    "    imputation_clean_no_oh['ABO_DON'] = imputation_clean_no_oh['ABO_DON'].str.replace(\"A1\", \"A\", case=False, regex=False)\n",
    "    # Replace all instances of \"A2\" with \"A\" in column: 'ABO_DON'\n",
    "    imputation_clean_no_oh['ABO_DON'] = imputation_clean_no_oh['ABO_DON'].str.replace(\"A2\", \"A\", case=False, regex=False)\n",
    "    # One-hot encode column: 'ABO_DON'\n",
    "    insert_loc = imputation_clean_no_oh.columns.get_loc('ABO_DON')\n",
    "    imputation_clean_no_oh = pd.concat([imputation_clean_no_oh.iloc[:,:insert_loc], pd.get_dummies(imputation_clean_no_oh.loc[:, ['ABO_DON']]), imputation_clean_no_oh.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \"M\" with \"0\" in column: 'GENDER_DON'\n",
    "    imputation_clean_no_oh['GENDER_DON'] = imputation_clean_no_oh['GENDER_DON'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"F\" with \"1\" in column: 'GENDER_DON'\n",
    "    imputation_clean_no_oh['GENDER_DON'] = imputation_clean_no_oh['GENDER_DON'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"999\" with \"0\" in column: 'ART_RECON'\n",
    "    imputation_clean_no_oh['ART_RECON'] = imputation_clean_no_oh['ART_RECON'].str.replace(\"999\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"3\" with \"0\" in column: 'ART_RECON'\n",
    "    imputation_clean_no_oh['ART_RECON'] = imputation_clean_no_oh['ART_RECON'].str.replace(\"3\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"1\" with \"0\" in column: 'ART_RECON'\n",
    "    imputation_clean_no_oh['ART_RECON'] = imputation_clean_no_oh['ART_RECON'].str.replace(\"1\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"4\" with \"0\" in column: 'ART_RECON'\n",
    "    imputation_clean_no_oh['ART_RECON'] = imputation_clean_no_oh['ART_RECON'].str.replace(\"4\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5\" with \"0\" in column: 'ART_RECON'\n",
    "    imputation_clean_no_oh['ART_RECON'] = imputation_clean_no_oh['ART_RECON'].str.replace(\"5\", \"0\", case=False, regex=False)\n",
    "    # Rename column 'ART_RECON' to 'ART_RECON_is2'\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.rename(columns={'ART_RECON': 'ART_RECON_is2'})\n",
    "    # Replace all instances of \"2\" with \"1\" in column: 'ART_RECON_is2'\n",
    "    imputation_clean_no_oh['ART_RECON_is2'] = imputation_clean_no_oh['ART_RECON_is2'].str.replace(\"2\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"4\" with \"999\" in column: 'DUCT_MGMT'\n",
    "    imputation_clean_no_oh['DUCT_MGMT'] = imputation_clean_no_oh['DUCT_MGMT'].str.replace(\"4\", \"999\", case=False, regex=False)\n",
    "    # Replace all instances of \"5\" with \"999\" in column: 'DUCT_MGMT'\n",
    "    imputation_clean_no_oh['DUCT_MGMT'] = imputation_clean_no_oh['DUCT_MGMT'].str.replace(\"5\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DUCT_MGMT'\n",
    "    insert_loc = imputation_clean_no_oh.columns.get_loc('DUCT_MGMT')\n",
    "    imputation_clean_no_oh = pd.concat([imputation_clean_no_oh.iloc[:,:insert_loc], pd.get_dummies(imputation_clean_no_oh.loc[:, ['DUCT_MGMT']]), imputation_clean_no_oh.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \"2\" with \"0\" in column: 'GRF_PLACEM'\n",
    "    imputation_clean_no_oh['GRF_PLACEM'] = imputation_clean_no_oh['GRF_PLACEM'].str.replace(\"2\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"3\" with \"0\" in column: 'GRF_PLACEM'\n",
    "    imputation_clean_no_oh['GRF_PLACEM'] = imputation_clean_no_oh['GRF_PLACEM'].str.replace(\"3\", \"0\", case=False, regex=False)\n",
    "    # Rename column 'GRF_PLACEM' to 'GRF_PLACEM_is1'\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.rename(columns={'GRF_PLACEM': 'GRF_PLACEM_is1'})\n",
    "    # Replace all instances of \"2\" with \"0\" in column: 'VASC_MGMT'\n",
    "    imputation_clean_no_oh['VASC_MGMT'] = imputation_clean_no_oh['VASC_MGMT'].str.replace(\"2\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"3\" with \"0\" in column: 'VASC_MGMT'\n",
    "    imputation_clean_no_oh['VASC_MGMT'] = imputation_clean_no_oh['VASC_MGMT'].str.replace(\"3\", \"0\", case=False, regex=False)\n",
    "    # Rename column 'VASC_MGMT' to 'VASC_MGMT_is1'\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.rename(columns={'VASC_MGMT': 'VASC_MGMT_is1'})\n",
    "    imputation_clean_no_oh['EBV_SEROSTATUS'] = imputation_clean_no_oh['EBV_SEROSTATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HBV_CORE'] = imputation_clean_no_oh['HBV_CORE'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HCV_SEROSTATUS'] = imputation_clean_no_oh['HCV_SEROSTATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CMV_STATUS'] = imputation_clean_no_oh['CMV_STATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['EBV_SEROSTATUS'] = imputation_clean_no_oh['EBV_SEROSTATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HBV_CORE'] = imputation_clean_no_oh['HBV_CORE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HCV_SEROSTATUS'] = imputation_clean_no_oh['HCV_SEROSTATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['EBV_SEROSTATUS'] = imputation_clean_no_oh['EBV_SEROSTATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HBV_CORE'] = imputation_clean_no_oh['HBV_CORE'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['HCV_SEROSTATUS'] = imputation_clean_no_oh['HCV_SEROSTATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_clean_no_oh['CMV_STATUS'] = imputation_clean_no_oh['CMV_STATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"0D\" with \"0\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation_clean_no_oh['EBV_SEROSTATUS'] = imputation_clean_no_oh['EBV_SEROSTATUS'].str.replace(\"0D\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'CMV_STATUS'\n",
    "    imputation_clean_no_oh['CMV_STATUS'] = imputation_clean_no_oh['CMV_STATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # One-hot encode column: 'TX_TYPE'\n",
    "    insert_loc = imputation_clean_no_oh.columns.get_loc('TX_TYPE')\n",
    "    imputation_clean_no_oh = pd.concat([imputation_clean_no_oh.iloc[:,:insert_loc], pd.get_dummies(imputation_clean_no_oh.loc[:, ['TX_TYPE']]), imputation_clean_no_oh.iloc[:,insert_loc+1:]], axis=1)\n",
    "     # Replace all instances of \"5001\" with \"1\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5001\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"5002\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5002\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5003\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5003\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5000\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5000\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"999\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"999\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5009\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5009\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5008\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5008\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5005\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5005\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5007\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5007\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5004\" with \"\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5004\", \"\", case=False, regex=False)\n",
    "    # Replace all instances of \"\" with \"\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh.loc[imputation_clean_no_oh['DIAG_PA'].str.lower() == \"\".lower(), 'DIAG_PA'] = \"0\"\n",
    "    # Replace all instances of \"5006\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_clean_no_oh['DIAG_PA'] = imputation_clean_no_oh['DIAG_PA'].str.replace(\"5006\", \"0\", case=False, regex=False)\n",
    "    # Rename column 'DIAG_PA' to 'DIAG_PA_is5001'\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.rename(columns={'DIAG_PA': 'DIAG_PA_is5001'})\n",
    "\n",
    "    # Change column type to float32 for columns: 'GENDER', 'ABO_A' and 108 other columns\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.astype({'GENDER': 'float32', 'ABO_A': 'float32', 'ABO_AB': 'float32', 'ABO_B': 'float32', 'ABO_O': 'float32', 'PERIP_VASC': 'float32', 'AGE_DIAB': 'float32', 'CREAT_TRR': 'float32', 'AMIS': 'float32', 'BMIS': 'float32', 'DRMIS': 'float32', 'HLAMIS': 'float32', 'NPKID': 'float32', 'NPPAN': 'float32', 'AGE_DON': 'float32', 'DDAVP_DON': 'float32', 'CMV_DON': 'float32', 'ABO_DON_A': 'float32', 'ABO_DON_AB': 'float32', 'ABO_DON_B': 'float32', 'ABO_DON_O': 'float32', 'GENDER_DON': 'float32', 'NON_HRT_DON': 'float32', 'ANTIHYPE_DON': 'float32',  'BUN_DON': 'float32', 'CREAT_DON': 'float32', 'PT_DIURETICS_DON': 'float32', 'PT_STEROIDS_DON': 'float32', 'PT_T3_DON': 'float32', 'PT_T4_DON': 'float32', 'SGOT_DON': 'float32', 'SGPT_DON': 'float32', 'TBILI_DON': 'float32', 'VASODIL_DON': 'float32', 'CLIN_INFECT_DON': 'float32', 'HIST_CIG_DON': 'float32', 'HIST_COCAINE_DON': 'float32', 'HIST_HYPERTENS_DON': 'float32', 'HIST_OTH_DRUG_DON': 'float32', 'HEPARIN_DON': 'float32', 'HGT_CM_DON_CALC': 'float32', 'WGT_KG_DON_CALC': 'float32', 'BMI_DON_CALC': 'float32', 'ABO_MAT': 'float32', 'AGE': 'float32', 'DIAL_TRR': 'float32', 'MULTIORG': 'float32', 'ART_RECON_is2': 'float32', 'DUCT_MGMT_1': 'float32', 'DUCT_MGMT_2': 'float32', 'DUCT_MGMT_3': 'float32', 'DUCT_MGMT_999': 'float32', 'GRF_PLACEM_is1': 'float32', 'PA_PRESERV_TM': 'float32', 'VASC_MGMT_is1': 'float32', 'VEN_EXT_GRF': 'float32', 'DIAG_PA_is5001': 'float32', 'DAYSWAIT_CHRON_PA': 'float32', 'EBV_SEROSTATUS': 'float32', 'HBV_CORE': 'float32', 'HCV_SEROSTATUS': 'float32', 'CMV_STATUS': 'float32', 'TX_TYPE_PAK': 'float32', 'TX_TYPE_PTA': 'float32', 'TX_TYPE_PWK': 'float32', 'TX_TYPE_SKP': 'float32', 'MALIG': 'float32', 'HGT_CM_CALC': 'float32', 'WGT_KG_CALC': 'float32', 'BMI_CALC': 'float32', 'PROTEIN_URINE': 'float32', 'CARDARREST_NEURO': 'float32',  'INOTROP_SUPPORT_DON': 'float32'})\n",
    "\n",
    "    # Replace all instances of \"N\" with \"1\" in column: 'GRF_STAT_PA'\n",
    "    imputation_clean_no_oh['GRF_STAT_PA'] = imputation_clean_no_oh['GRF_STAT_PA'].str.replace(\"N\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"0\" in column: 'GRF_STAT_PA'\n",
    "    imputation_clean_no_oh['GRF_STAT_PA'] = imputation_clean_no_oh['GRF_STAT_PA'].str.replace(\"Y\", \"0\", case=False, regex=False)\n",
    "    # Change column type to float32 for column: 'GRF_STAT_PA'\n",
    "    imputation_clean_no_oh = imputation_clean_no_oh.astype({'GRF_STAT_PA': 'float32'})\n",
    "    \n",
    "    return imputation_clean_no_oh\n",
    "\n",
    "imputation_clean_no_oh_clean = clean_data(imputation_clean_no_oh.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(imputation_new):\n",
    "    # Replace all instances of \"M\" with \"0\" in columns: 'GENDER', 'GENDER_DON'\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"F\" with \"1\" in columns: 'GENDER', 'GENDER_DON'\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"N\" in columns: 'PERIP_VASC', 'DDAVP_DON' and 17 other columns\n",
    "    imputation_new['PERIP_VASC'] = imputation_new['PERIP_VASC'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['DDAVP_DON'] = imputation_new['DDAVP_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['ANTIHYPE_DON'] = imputation_new['ANTIHYPE_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_DIURETICS_DON'] = imputation_new['PT_DIURETICS_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_STEROIDS_DON'] = imputation_new['PT_STEROIDS_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_T3_DON'] = imputation_new['PT_T3_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['VASODIL_DON'] = imputation_new['VASODIL_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['CLIN_INFECT_DON'] = imputation_new['CLIN_INFECT_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_CIG_DON'] = imputation_new['HIST_CIG_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_HYPERTENS_DON'] = imputation_new['HIST_HYPERTENS_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_T4_DON'] = imputation_new['PT_T4_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_COCAINE_DON'] = imputation_new['HIST_COCAINE_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_OTH_DRUG_DON'] = imputation_new['HIST_OTH_DRUG_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['MALIG'] = imputation_new['MALIG'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PROTEIN_URINE'] = imputation_new['PROTEIN_URINE'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['CARDARREST_NEURO'] = imputation_new['CARDARREST_NEURO'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['INOTROP_SUPPORT_DON'] = imputation_new['INOTROP_SUPPORT_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"Y\" in columns: 'HEPARIN_DON', 'DIAL_TRR'\n",
    "    imputation_new['HEPARIN_DON'] = imputation_new['HEPARIN_DON'].str.replace(\"U\", \"Y\", case=False, regex=False)\n",
    "    imputation_new['DIAL_TRR'] = imputation_new['DIAL_TRR'].str.replace(\"U\", \"Y\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in columns: 'GENDER', 'ABO' and 34 other columns\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['ABO'] = imputation_new['ABO'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PERIP_VASC'] = imputation_new['PERIP_VASC'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DDAVP_DON'] = imputation_new['DDAVP_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['ABO_DON'] = imputation_new['ABO_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['ANTIHYPE_DON'] = imputation_new['ANTIHYPE_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_DIURETICS_DON'] = imputation_new['PT_DIURETICS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_STEROIDS_DON'] = imputation_new['PT_STEROIDS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_T3_DON'] = imputation_new['PT_T3_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['VASODIL_DON'] = imputation_new['VASODIL_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CLIN_INFECT_DON'] = imputation_new['CLIN_INFECT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_CIG_DON'] = imputation_new['HIST_CIG_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_HYPERTENS_DON'] = imputation_new['HIST_HYPERTENS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_T4_DON'] = imputation_new['PT_T4_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_COCAINE_DON'] = imputation_new['HIST_COCAINE_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_OTH_DRUG_DON'] = imputation_new['HIST_OTH_DRUG_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HEPARIN_DON'] = imputation_new['HEPARIN_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DIAL_TRR'] = imputation_new['DIAL_TRR'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GRF_PLACEM'] = imputation_new['GRF_PLACEM'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['VASC_MGMT'] = imputation_new['VASC_MGMT'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GRF_STAT_PA'] = imputation_new['GRF_STAT_PA'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['TX_TYPE'] = imputation_new['TX_TYPE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['MALIG'] = imputation_new['MALIG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PROTEIN_URINE'] = imputation_new['PROTEIN_URINE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['LIPASE'] = imputation_new['LIPASE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['AMYLASE'] = imputation_new['AMYLASE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CARDARREST_NEURO'] = imputation_new['CARDARREST_NEURO'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['INOTROP_SUPPORT_DON'] = imputation_new['INOTROP_SUPPORT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in columns: 'GENDER', 'ABO' and 34 other columns\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['ABO'] = imputation_new['ABO'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PERIP_VASC'] = imputation_new['PERIP_VASC'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DDAVP_DON'] = imputation_new['DDAVP_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['ABO_DON'] = imputation_new['ABO_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['ANTIHYPE_DON'] = imputation_new['ANTIHYPE_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_DIURETICS_DON'] = imputation_new['PT_DIURETICS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_STEROIDS_DON'] = imputation_new['PT_STEROIDS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_T3_DON'] = imputation_new['PT_T3_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['VASODIL_DON'] = imputation_new['VASODIL_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CLIN_INFECT_DON'] = imputation_new['CLIN_INFECT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_CIG_DON'] = imputation_new['HIST_CIG_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_HYPERTENS_DON'] = imputation_new['HIST_HYPERTENS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_T4_DON'] = imputation_new['PT_T4_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_COCAINE_DON'] = imputation_new['HIST_COCAINE_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_OTH_DRUG_DON'] = imputation_new['HIST_OTH_DRUG_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HEPARIN_DON'] = imputation_new['HEPARIN_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DIAL_TRR'] = imputation_new['DIAL_TRR'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GRF_PLACEM'] = imputation_new['GRF_PLACEM'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['VASC_MGMT'] = imputation_new['VASC_MGMT'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GRF_STAT_PA'] = imputation_new['GRF_STAT_PA'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['TX_TYPE'] = imputation_new['TX_TYPE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['MALIG'] = imputation_new['MALIG'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PROTEIN_URINE'] = imputation_new['PROTEIN_URINE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['LIPASE'] = imputation_new['LIPASE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['AMYLASE'] = imputation_new['AMYLASE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CARDARREST_NEURO'] = imputation_new['CARDARREST_NEURO'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['INOTROP_SUPPORT_DON'] = imputation_new['INOTROP_SUPPORT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Change column type to string for columns: 'COD_CAD_DON', 'DEATH_CIRCUM_DON' and 5 other columns\n",
    "    imputation_new = imputation_new.astype({'COD_CAD_DON': 'string', 'DEATH_CIRCUM_DON': 'string', 'DEATH_MECH_DON': 'string', 'ART_RECON': 'string', 'DUCT_MGMT': 'string', 'DIAG_PA': 'string', 'OPER_TECH': 'string'})\n",
    "    # Replace all instances of \"P\" with \"1\" in columns: 'EBV_SEROSTATUS', 'HBV_CORE' and 2 other columns\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"0\" in columns: 'EBV_SEROSTATUS', 'HBV_CORE' and 2 other columns\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"0D\" with \"0\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"0D\", \"0\", case=False, regex=False)\n",
    "    # Replace missing values with \"0\" in columns: 'EBV_SEROSTATUS', 'HBV_CORE' and 2 other columns\n",
    "    imputation_new = imputation_new.fillna({'EBV_SEROSTATUS': \"0\", 'HBV_CORE': \"0\", 'HCV_SEROSTATUS': \"0\", 'CMV_STATUS': \"0\"})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'LIPASE', 'AMYLASE'\n",
    "    imputation_new.loc[imputation_new['LIPASE'].str.lower() == \".\".lower(), 'LIPASE'] = np.nan\n",
    "    imputation_new.loc[imputation_new['AMYLASE'].str.lower() == \".\".lower(), 'AMYLASE'] = np.nan\n",
    "    # Change column type to float32 for columns: 'LIPASE', 'AMYLASE'\n",
    "    imputation_new = imputation_new.astype({'LIPASE': 'float32', 'AMYLASE': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'LIPASE', 'AMYLASE'\n",
    "    imputation_new = imputation_new.fillna({'LIPASE': imputation_new['LIPASE'].median(), 'AMYLASE': imputation_new['AMYLASE'].median()})\n",
    "    # One-hot encode column: 'TX_TYPE'\n",
    "    insert_loc = imputation_new.columns.get_loc('TX_TYPE')\n",
    "    imputation_new = pd.concat([imputation_new.iloc[:,:insert_loc], pd.get_dummies(imputation_new.loc[:, ['TX_TYPE']]), imputation_new.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Drop columns: 'COD_CAD_DON', 'DEATH_CIRCUM_DON', 'DEATH_MECH_DON'\n",
    "    imputation_new = imputation_new.drop(columns=['COD_CAD_DON', 'DEATH_CIRCUM_DON', 'DEATH_MECH_DON'])\n",
    "    return imputation_new\n",
    "\n",
    "imputation_new_clean = clean_data(imputation_new.copy())\n",
    "imputation_new_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean_no_oh_clean[imputation_clean_no_oh_clean.select_dtypes(include=['bool']).columns] = imputation_clean_no_oh_clean.select_dtypes(include=['bool']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_clean_no_oh_clean = imputation_clean_no_oh_clean.drop(columns=[\"TRR_ID_CODE\", \"ETHCAT\", \"ETHCAT_DON\", \"TX_TYPE_SKP\", \"TX_PROCEDUR_TY_PA\", \"ABO_A\", \"ABO_B\", \"ABO_AB\", \"ABO_O\", \"ABO_DON_A\", \"ABO_DON_B\", \"ABO_DON_AB\", \"ABO_DON_O\", \"TX_TYPE_PAK\", \"DEATH_MECH_DON\", \"DEATH_CIRCUM_DON\", \"COD_CAD_DON\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# imputation_clean_no_oh_clean = pd.DataFrame(scaler.fit_transform(imputation_clean_no_oh_clean), columns=imputation_clean_no_oh_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean_no_oh_clean[imputation_clean_no_oh_clean.select_dtypes(include=['int']).columns] = imputation_clean_no_oh_clean.select_dtypes(include=['int']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean_no_oh_clean.to_csv(\"data_ready_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
